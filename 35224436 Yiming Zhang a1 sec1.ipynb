{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d82c02",
   "metadata": {},
   "source": [
    "### 1 Model Complexity and Model Selection\n",
    "### Student ID: 35224436 | Full name: Yiming Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d605122",
   "metadata": {},
   "source": [
    "## 1.1 Question 1 KNN Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef49af",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea44f0b",
   "metadata": {},
   "source": [
    "### KNN Regressor Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnRegressor(BaseEstimator):\n",
    "    def __init__(self, k=5): # ADD PARAMETERS AS REQUIRED\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.y_train_ = y\n",
    "        self.x_train_kdtree_ = KDTree(x)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        _, neighbours = self.x_train_kdtree_.query(x, k=self.k)\n",
    "        neighbours = neighbours.reshape(len(x), self.k)\n",
    "        neighbour_labels = self.y_train_[neighbours]\n",
    "        return np.mean(neighbour_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c9e89",
   "metadata": {},
   "source": [
    "### Test implementation\n",
    "测试准备，分割测试集和训练集的工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb50cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, train_size=0.6, random_state=None):\n",
    "    \"\"\"Split the data into training and testing sets\"\"\"\n",
    "    RNG = np.random.default_rng(random_state)\n",
    "    N = len(x)\n",
    "    N_train = round(N * train_size)\n",
    "    idx_train = RNG.choice(N, N_train, replace=False)\n",
    "    idx_test = np.setdiff1d(np.arange(N), idx_train)\n",
    "    RNG.shuffle(idx_test)\n",
    "    return x[idx_train], x[idx_test], y[idx_train], y[idx_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924cd816",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6711087",
   "metadata": {},
   "source": [
    "#### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287128e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=1024\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc4ad51",
   "metadata": {},
   "source": [
    "#### Guess a K\n",
    "依据经验法则, $\\sqrt{traingSetSize}\\,$ 往往接近最优K的取值。因此我猜测 K = $\\sqrt{309} \\approx$ 18 为可接受的 K 取值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc73fe",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fa6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test KNN Regressor\n",
    "knn = KnnRegressor(k=18)\n",
    "knn.fit(X_train, y_train)\n",
    "y_hat_train = knn.predict(X_train)\n",
    "y_hat_test = knn.predict(X_test)\n",
    "y_hat_train, y_hat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4086f",
   "metadata": {},
   "source": [
    "### Evaulation\n",
    "用 the sum of the squares of the errors 作为 error function 来衡量  training errors and testing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0928f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of squared errors\n",
    "def sse(y_true, y_pred):\n",
    "    return np.sum((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de989f6",
   "metadata": {},
   "source": [
    "#### 计算error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_train = sse(y_train, y_hat_train)\n",
    "sse_test = sse(y_test, y_hat_test)\n",
    "sse_train, sse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7a35b",
   "metadata": {},
   "source": [
    "#### Further test to find optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_k(X_train, y_train, X_test, y_test, max_k):\n",
    "    \"\"\"\n",
    "    Choose the best K for KNN Regressor\n",
    "    max_k: the maximum K to test\n",
    "    \"\"\"\n",
    "    sse_train = []\n",
    "    sse_test = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        knn = KnnRegressor(k=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_hat_train = knn.predict(X_train)\n",
    "        y_hat_test = knn.predict(X_test)\n",
    "        sse_train.append(sse(y_train, y_hat_train))\n",
    "        sse_test.append(sse(y_test, y_hat_test))\n",
    "    return sse_train, sse_test\n",
    "\n",
    "sse_train, sse_test = choose_k(X_train, y_train, X_test, y_test, 30)\n",
    "\n",
    "# find the minimum sse_test and the corresponding k\n",
    "min_sse_test = min(sse_test)\n",
    "k_min = sse_test.index(min_sse_test) + 1\n",
    "print(f\"The minimum testing error is {min_sse_test} when K = {k_min}\")\n",
    "print(f\"Hence, the optimal K is {k_min}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508f03e",
   "metadata": {},
   "source": [
    "## 1.2 Question 2 L-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291160ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFold:\n",
    "    def __init__(self, L = 5): # ADD PARAMETERS AS REQUIRED\n",
    "        # YOUR CODE HERE\n",
    "        self.L = L\n",
    "    def get_n_splits(self, x=None, y=None, groups=None):\n",
    "        # split the data into L folds\n",
    "        N = len(x)\n",
    "        N_fold = N // self.L\n",
    "        for i in range(self.L):\n",
    "            test_idx = np.arange(i*N_fold, (i+1)*N_fold)\n",
    "            train_idx = np.setdiff1d(np.arange(N), test_idx)\n",
    "            yield train_idx, test_idx\n",
    "    \n",
    "    def split(self, x, y=None, groups=None):\n",
    "        # YOUR CODE HERE\n",
    "        yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa4419",
   "metadata": {},
   "source": [
    "## 1.3 Question 3 Automatic Model Selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
