{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc67fef5",
   "metadata": {},
   "source": [
    "## 3 Logistic Regression versus Bayes Classifier\n",
    "### Student ID: 35224436 | Full name: Yiming Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012502d0",
   "metadata": {},
   "source": [
    "## Task I. The Bayesian Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334d017b",
   "metadata": {},
   "source": [
    "### 1. Data preparation\n",
    "Load the data and output some descriptive information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# print the first 5 rows of the data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3a6fc",
   "metadata": {},
   "source": [
    "Data splitting with train_size=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d354f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a3e4e",
   "metadata": {},
   "source": [
    "### 2. Bayesian Classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BayesianClassifier:\n",
    "    def __init__(self, shared_cov=True, cond_ind=True):\n",
    "        self.shared_cov = shared_cov  # whether to share the covariance matrix\n",
    "        self.cond_ind = cond_ind  # whether to assume conditional independence\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # get the classes and their counts\n",
    "        self.classes_, class_counts = np.unique(y, return_counts=True)\n",
    "        self.n_, self.p_ = x.shape  # get sample number and feature number\n",
    "        self.k_ = len(self.classes_)  # [0, 1, 2, ..., k-1]\n",
    "\n",
    "        # initialize the conditional means and covariance matrices\n",
    "        self.cond_means_ = np.zeros(shape=(self.k_, self.p_))\n",
    "        self.cond_covs_ = np.zeros(shape=(self.k_, self.p_, self.p_))\n",
    "\n",
    "        # calculate the prior probabilities\n",
    "        self.class_priors_ = class_counts / len(y)\n",
    "\n",
    "        # calculate the conditional means and covariance matrices for each class\n",
    "        for c in range(self.k_):\n",
    "            c_rows = y == c\n",
    "\n",
    "            self.cond_means_[c, :] = x[c_rows].mean(axis=0)\n",
    "\n",
    "            if self.cond_ind:\n",
    "                # conditional independence -> diagonal matrix\n",
    "                np.fill_diagonal(self.cond_covs_[c, :, :], x[c_rows].var(axis=0))\n",
    "            else:\n",
    "                self.cond_covs_[c, :, :] = np.cov(x[c_rows].T, bias=True)\n",
    "\n",
    "        if self.shared_cov:\n",
    "            # calculate the shared covariance matrix\n",
    "            # weighted average of the covariance matrices of each class\n",
    "            shared_cov = np.moveaxis(self.cond_covs_, 0, -1).dot(self.class_priors_)\n",
    "            self.cond_covs_[:] = shared_cov\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        m, _ = x.shape\n",
    "        cond_probs = np.zeros(shape=(m, self.k_))\n",
    "        for c in range(self.k_):\n",
    "            # find p(x | c_k)\n",
    "            # singular covariance matrices could happen (e.g., through inaccurate estimation)\n",
    "            cond_probs[:, c] = multivariate_normal.pdf(\n",
    "                x, self.cond_means_[c], self.cond_covs_[c], allow_singular=True\n",
    "            )\n",
    "        # find marginal probabilities p(x) by summing all the conditionals weighted by the priors\n",
    "        marginal_probs = cond_probs.dot(self.class_priors_)\n",
    "\n",
    "        # find probability vector (p(c1 | x), ..., p(ck | x)) via p(ci | x)=p(x | ci) / p(x)\n",
    "        # however, p(x) might have been rounded to 0\n",
    "        # thus, compute via case distinction\n",
    "        probs = np.divide(\n",
    "            (cond_probs * self.class_priors_).T,\n",
    "            marginal_probs,\n",
    "            where=marginal_probs > 0,\n",
    "            out=np.zeros(shape=(self.k_, m)),\n",
    "        ).T\n",
    "        return probs\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.argmax(self.predict_proba(x), axis=1)\n",
    "\n",
    "    def decision_function(self, x):\n",
    "        probs = self.predict_proba(x)\n",
    "        if self.k_ == 2:\n",
    "            return np.log(probs[:, 1] / probs[:, 0])\n",
    "        else:\n",
    "            res = np.zeros(len(x), self.k_)\n",
    "            for c in range(self.k_):\n",
    "                res[:, c] = np.log(probs[:, c] / (1 - probs[:, c]))\n",
    "            return res\n",
    "\n",
    "    def generate(self, n, c, random_state=None):\n",
    "        return multivariate_normal.rvs(\n",
    "            self.cond_means_[c], self.cond_covs_[c], size=n, random_state=random_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59f70d",
   "metadata": {},
   "source": [
    "### 3. Variants of Bayesian Classifiers\n",
    "In this section, we define three types of Bayesian classifiers: the Naive Bayes variant (without shared covariance), as well as the variants with full covariance (both shared and not shared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes variant\n",
    "naive_bayes = BayesianClassifier(shared_cov=False, cond_ind=True)\n",
    "# full covariance variant with shared covariance\n",
    "full_cov_shared = BayesianClassifier(shared_cov=True, cond_ind=False)\n",
    "# full covariance variant with not shared covariance\n",
    "full_cov_not_shared = BayesianClassifier(shared_cov=False, cond_ind=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbe29d",
   "metadata": {},
   "source": [
    "### 4. Training Process\n",
    "Use the training set obtained in the first step to train the three variants of Bayesian classifiers and the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Naive Bayes variant\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "# full covariance variant with shared covariance\n",
    "full_cov_shared.fit(X_train, y_train)\n",
    "# full covariance variant with not shared covariance\n",
    "full_cov_not_shared.fit(X_train, y_train)\n",
    "# logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b34f34",
   "metadata": {},
   "source": [
    "### 5. Evaulation Methods\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
